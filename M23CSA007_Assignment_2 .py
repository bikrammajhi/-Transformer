# -*- coding: utf-8 -*-
"""M23CSA007.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PbuY6NiC2vNP6Cq9Uqnk4b6DvPMatbnM
"""

# Commented out IPython magic to ensure Python compatibility.
# Installing the requirements
print('Installing Requirements... ',end='')
!pip install lightning
!pip install torchsummary
!pip3 install wandb
# %pip install sox
print('Done')

# !pip install wandb -qqq
# import wandb
# # wandb.login()

# Importing Libraries
print('Importing Libraries... ',end='')
import os
from pathlib import Path
import pandas as pd
# from torchsummary import summary
import torchaudio
import zipfile
from torchaudio.transforms import Resample
import IPython.display as ipd
from matplotlib import pyplot as plt
from tqdm import tqdm
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
from torchaudio import load
from torchvision import transforms
import torch

import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
import wandb
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix
from sklearn.model_selection import KFold
from torch.utils.data import ConcatDataset
from torch.utils.data import DataLoader, Subset
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, f1_score

print('Done')

# # Extract data
# with zipfile.ZipFile("/teamspace/studios/this_studio/audio8k.zip", 'r') as zip_ref:
#     zip_ref.extractall("/teamspace/studios/this_studio/audio8k")

# Loading dataset
path = Path('/teamspace/studios/this_studio/audio8k')
df = pd.read_csv('/teamspace/studios/this_studio/audio8k/meta/esc50.csv')

# Getting list of raw audio files
wavs = list(path.glob('audio/*'))  # List all audio files in the 'audio' directory using pathlib.Path.glob

# Visualizing data
waveform, sample_rate = torchaudio.load(str(wavs[0]))  # Load the waveform and sample rate of the first audio file using torchaudio

print("Shape of waveform: {}".format(waveform.size()))  # Print the shape of the waveform tensor
print("Sample rate of waveform: {}".format(sample_rate))  # Print the sample rate of the audio file

# Plot the waveform using matplotlib
plt.figure()
plt.plot(waveform.t().numpy())  # Transpose and convert the waveform tensor to a NumPy array for plotting


# Display the audio using IPython.display.Audio
ipd.Audio(waveform, rate=sample_rate)  # Create an interactive audio player for the loaded waveform

class CustomDataset(Dataset):
    def __init__(self, dataset, **kwargs):
        # Initialize CustomDataset object with relevant parameters
        # dataset: "train", "val", or "test"
        # kwargs: Additional parameters like data directory, dataframe, folds, etc.

        # Extract parameters from kwargs
        self.data_directory = kwargs["data_directory"]
        self.data_frame = kwargs["data_frame"]
        self.validation_fold = kwargs["validation_fold"]
        self.testing_fold = kwargs["testing_fold"]
        self.esc_10_flag = kwargs["esc_10_flag"]
        self.file_column = kwargs["file_column"]
        self.label_column = kwargs["label_column"]
        self.sampling_rate = kwargs["sampling_rate"]
        self.new_sampling_rate = kwargs["new_sampling_rate"]
        self.sample_length_seconds = kwargs["sample_length_seconds"]

        # Filter dataframe based on esc_10_flag and data_type
        if self.esc_10_flag:
            self.data_frame = self.data_frame.loc[self.data_frame['esc10'] == True]

        if dataset == "train":
            self.data_frame = self.data_frame.loc[
                (self.data_frame['fold'] != self.validation_fold) & (self.data_frame['fold'] != self.testing_fold)]
        elif dataset == "val":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.validation_fold]
        elif dataset == "test":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.testing_fold]

        # Get unique categories from the filtered dataframe
        self.categories = sorted(self.data_frame[self.label_column].unique())

        # Initialize lists to hold file names, labels, and folder numbers
        self.file_names = []
        self.labels = []

        # Initialize dictionaries for category-to-index and index-to-category mapping
        self.category_to_index = {}
        self.index_to_category = {}

        for i, category in enumerate(self.categories):
            self.category_to_index[category] = i
            self.index_to_category[i] = category

        # Populate file names and labels lists by iterating through the dataframe
        for ind in tqdm(range(len(self.data_frame))):
            row = self.data_frame.iloc[ind]
            file_path = self.data_directory / "audio" / row[self.file_column]
            self.file_names.append(file_path)
            self.labels.append(self.category_to_index[row[self.label_column]])

        self.resampler = torchaudio.transforms.Resample(self.sampling_rate, self.new_sampling_rate)

        # Window size for rolling window sample splits (unfold method)
        if self.sample_length_seconds == 2:
            self.window_size = self.new_sampling_rate * 2
            self.step_size = int(self.new_sampling_rate * 0.75)
        else:
            self.window_size = self.new_sampling_rate
            self.step_size = int(self.new_sampling_rate * 0.5)

    def __getitem__(self, index):
        # Split audio files with overlap, pass as stacked tensors tensor with a single label
        path = self.file_names[index]
        audio_file = torchaudio.load(str(path), format=None, normalize=True)
        audio_tensor = self.resampler(audio_file[0])

        # Normalize the audio tensor
        audio_tensor = (audio_tensor - audio_tensor.mean()) / audio_tensor.std()

        splits = audio_tensor.unfold(1, self.window_size, self.step_size)
        samples = splits.permute(1, 0, 2)
        return samples, self.labels[index]

    def __len__(self):
        return len(self.file_names)

class CustomDataModule(pl.LightningDataModule):
    def __init__(self, **kwargs):
        # Initialize the CustomDataModule with batch size, number of workers, and other parameters
        super().__init__()
        self.batch_size = kwargs["batch_size"]
        self.num_workers = kwargs["num_workers"]
        self.data_module_kwargs = kwargs

    def setup(self, stage=None):
        # Define datasets for training, validation, and testing during Lightning setup

        # If in 'fit' or None stage, create training and validation datasets
        if stage == 'fit' or stage is None:
            self.training_dataset = CustomDataset(dataset="train", **self.data_module_kwargs)
            self.validation_dataset = CustomDataset(dataset="val", **self.data_module_kwargs)

        # If in 'test' or None stage, create testing dataset
        if stage == 'test' or stage is None:
            self.testing_dataset = CustomDataset(dataset="test", **self.data_module_kwargs)

    def train_dataloader(self):
        # Return DataLoader for training dataset
        return DataLoader(self.training_dataset,
                          batch_size=self.batch_size,
                          shuffle=True,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def val_dataloader(self):
        # Return DataLoader for validation dataset
        return DataLoader(self.validation_dataset,
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def test_dataloader(self):
        # Return DataLoader for testing dataset
        return DataLoader(self.testing_dataset,
                          batch_size=16, #16
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def collate_function(self, data):
        """
        Collate function to process a batch of examples and labels.

        Args:
            data: a tuple of 2 tuples with (example, label) where
                example are the split 1 second sub-frame audio tensors per file
                label = the label

        Returns:
            A list containing examples (concatenated tensors) and labels (flattened tensor).
        """
        examples, labels = zip(*data)
        examples = torch.stack(examples)
        examples = examples.view(examples.size(0), 9, -1)
        labels = torch.flatten(torch.tensor(labels))


        return [examples, labels]

# Data Setup
test_samp = 1 #""" Do not change this!! """
valid_samp = 4 # for k-fold validation asked in the question
batch_size = 16 # Free to change #16 working
num_workers = 2 # Free to change
custom_data_module = CustomDataModule(batch_size=batch_size,
                                      num_workers=num_workers,
                                      data_directory=path,
                                      data_frame=df,
                                      validation_fold=valid_samp,
                                      testing_fold=test_samp,  # set to 0 for no test set
                                      esc_10_flag=True,
                                      file_column='filename',
                                      label_column='category',
                                      sampling_rate=44100,
                                      new_sampling_rate=16000,  # new sample rate for input
                                      sample_length_seconds=1  # new length of input in seconds
                                      )

custom_data_module.setup()

# Data Exploration
print('Class Label: ', custom_data_module.training_dataset[0][1])  # this prints the class label
print('Shape of data sample tensor: ', custom_data_module.training_dataset[0][0].shape)  # this prints the shape of the sample (Frames, Channel, Features)

train_loader = custom_data_module.train_dataloader()
val_loader = custom_data_module.val_dataloader()
test_loader = custom_data_module.test_dataloader()

print(len(train_loader.dataset))

inp_data, labels = next(iter(train_loader))
print("Input data:", inp_data.shape)
print("Labels:    ", labels)

# Dataloader(s)
x = next(iter(custom_data_module.train_dataloader()))
y = next(iter(custom_data_module.val_dataloader()))
z = next(iter(custom_data_module.test_dataloader()))
print('Train Dataloader:')
print(x)
print('Validation Dataloader:')
print(y)
print('Test Dataloader:')
print(z)

import torch.nn as nn
import torch.nn.functional as F

class AudioClassifier(nn.Module):
    def __init__(self, num_classes=10):
        super(AudioClassifier, self).__init__()
        self.conv1 = nn.Conv1d(9, 128, kernel_size=80, stride=4)
        self.bn1 = nn.BatchNorm1d(128)
        self.pool1 = nn.MaxPool1d(4)
        self.conv2 = nn.Conv1d(128, 128, kernel_size=3)
        self.bn2 = nn.BatchNorm1d(128)
        self.pool2 = nn.MaxPool1d(4)
        self.conv3 = nn.Conv1d(128, 256, kernel_size=3)
        self.bn3 = nn.BatchNorm1d(256)
        self.pool3 = nn.MaxPool1d(4)
        self.conv4 = nn.Conv1d(256, 512, kernel_size=3)
        self.bn4 = nn.BatchNorm1d(512)
        self.pool4 = nn.MaxPool1d(4)
        self.avgPool = nn.AdaptiveAvgPool1d(1) # avgPool to make it invariant to input size
        self.fc1 = nn.Linear(512, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(self.bn1(x))
        x = self.pool1(x)
        x = self.conv2(x)
        x = F.relu(self.bn2(x))
        x = self.pool2(x)
        x = self.conv3(x)
        x = F.relu(self.bn3(x))
        x = self.pool3(x)
        x = self.conv4(x)
        x = F.relu(self.bn4(x))
        x = self.pool4(x)
        x = self.avgPool(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = F.log_softmax(x, dim=-2)
        return x

model = AudioClassifier(num_classes=10)

"""**Accuracy, Confusion Matrix, F1-scores, and AUC-ROC curve:**"""

def calculate_accuracy(outputs, labels):
    _, predicted = torch.max(outputs.data, 1)
    total = labels.size(0)
    correct = (predicted == labels).sum().item()
    return 100 * correct / total

def calculate_loss(criterion, outputs, labels):
    return criterion(outputs, labels).item()

! wandb login 11cb64ddf316ba2bd6cae84ceec30b3f88625c67

"""K-fold validation"""

# # epochs
# num_epoch = 100
# avg_validation_acc = []

# for fold in range(2,6):
#     # for heads in num_heads_list:
#         # Initialize a new wandb run
#         run = wandb.init(project=f" 1DCNN, Fold {fold}")

#         # # Get the hyperparameters
#         # hyperparameters = wandb.config
#         # print("hyper", hyperparameters)

#         # The model, optimizer, and loss
#         model =  AudioClassifier(num_classes=10)
#         optimizer = torch.optim.SGD(
#                                     model.parameters(),
#                                     lr=0.001,
#                                     momentum=0.9,
#                                     nesterov=True,
#                                     weight_decay=0.001
#                                 )

#         criterion = nn.CrossEntropyLoss()

#         #wandb.watch(model, criterion, log="all")

#         # Data Setup
#         test_samp = 1 #""" Do not change this!! """
#         valid_samp = fold # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
#         batch_size = 16 # Free to change #16 working
#         num_workers = 4 # Free to change
#         custom_data_module = CustomDataModule(batch_size=batch_size,
#                                             num_workers=num_workers,
#                                             data_directory=path,
#                                             data_frame=df,
#                                             validation_fold=valid_samp,
#                                             testing_fold=test_samp,  # set to 0 for no test set
#                                             esc_10_flag=True,
#                                             file_column='filename',
#                                             label_column='category',
#                                             sampling_rate=44100,
#                                             new_sampling_rate=16000,  # new sample rate for input
#                                             sample_length_seconds=1  # new length of input in seconds
#                                             )

#         custom_data_module.setup()

#         print(f"Training fold {fold}")

#         # wandb.init()


#         # Dataloader(s)
#         train_loader_fold = custom_data_module.train_dataloader()
#         val_loader_fold = custom_data_module.val_dataloader()
#         test_loader = custom_data_module.test_dataloader()


#         for epoch in range(num_epoch):
#             model.train()
#             running_loss = 0.0
#             total_samples = 0
#             total_correct = 0
#             for i, data in enumerate(train_loader_fold, 0):
#                 inputs, labels = data
#                 inputs =  inputs.view(inputs.size(0), -1,  inputs.size(-1))
#                 optimizer.zero_grad()
#                 outputs = model(inputs)

#                 loss = criterion(outputs, labels)
#                 loss.backward()
#                 optimizer.step()

#                 running_loss += loss.item()
#                 _, predicted = torch.max(outputs.data, 1)
#                 total_samples += labels.size(0)
#                 total_correct += (predicted == labels).sum().item()

#                 # # Step the scheduler
#                 # scheduler.step(epoch + i / len(train_loader))

#             # Log loss and accuracy
#             running_accuracy = 100 * total_correct / total_samples
#             wandb.log({"Epoch": epoch, "Training Loss": running_loss, "Training Accuracy": running_accuracy})

#         # Validation phase
#         model.eval()
#         running_loss = 0.0
#         total_samples = 0
#         total_correct = 0
#         with torch.no_grad():
#             for inputs, labels in val_loader_fold:
#                 inputs = inputs.view(inputs.size(0), -1, inputs.size(-1))
#                 outputs = model(inputs)

#                 running_loss += calculate_loss(criterion, outputs, labels)
#                 _, predicted = torch.max(outputs.data, 1)
#                 total_samples += labels.size(0)
#                 total_correct += (predicted == labels).sum().item()

#         # Log validation loss and accuracy
#         running_accuracy = 100 * total_correct / total_samples
#         wandb.log({"Epoch": epoch, "Validation Loss": running_loss, "Validation Accuracy": running_accuracy})


#         avg_validation_acc.append(running_accuracy)


#         # Testing phase
#         model.eval()
#         running_loss = 0.0
#         total_samples = 0
#         total_correct = 0

#         with torch.no_grad():
#             for inputs, labels in test_loader:
#                 inputs = inputs.view(inputs.size(0), -1, inputs.size(-1))
#                 outputs = model(inputs)
#                 _, predicted = torch.max(outputs.data, 1)
#                 total_samples += labels.size(0)
#                 total_correct += (predicted == labels).sum().item()

#                 running_loss += calculate_loss(criterion, outputs, labels)
#                 running_accuracy = 100 * total_correct / total_samples

#                 # Calculate test F1 Score
#                 test_f1 = f1_score(labels, predicted, average='weighted')

#                 # Log test loss and accuracy
#                 wandb.log({"Test Loss": running_loss, "Test Accuracy": running_accuracy, "Test F1 Score": test_f1})

#                 # Call the function to calculate and log ROC curves
#                 wandb.log({"roc" : wandb.plot.roc_curve(labels.detach().numpy(), outputs.detach().numpy(),  # outputs
#                                                             labels = [
#                                                             "Air Conditioner",
#                                                             "Car Horn",
#                                                             "Children Playing",
#                                                             "Dog Bark",
#                                                             "Drilling",
#                                                             "Engine Idling",
#                                                             "Gun Shot",
#                                                             "Jackhammer",
#                                                             "Siren",
#                                                             "Street Music"
#                                                         ]
#                                                         , classes_to_plot=None)})

#                 # Log Precision-Recall curve (for binary or specific class in multi-class)
#                 wandb.log({"pr" : wandb.plot.pr_curve(labels.detach().numpy(), outputs.detach().numpy(),
#                                                          labels = [
#                                                             "Air Conditioner",
#                                                             "Car Horn",
#                                                             "Children Playing",
#                                                             "Dog Bark",
#                                                             "Drilling",
#                                                             "Engine Idling",
#                                                             "Gun Shot",
#                                                             "Jackhammer",
#                                                             "Siren",
#                                                             "Street Music"
#                                                         ]
#                                                         , classes_to_plot=None)})

#                 # Log confusion matrix
#                 wandb.log({
#                     "conf_mat": wandb.plot.confusion_matrix(
#                         probs=None,
#                         y_true=labels.detach().numpy(),
#                         preds=outputs.argmax(dim=1).detach().numpy(),
#                         class_names= [
#                                         "Air Conditioner",
#                                         "Car Horn",
#                                         "Children Playing",
#                                         "Dog Bark",
#                                         "Drilling",
#                                         "Engine Idling",
#                                         "Gun Shot",
#                                         "Jackhammer",
#                                         "Siren",
#                                         "Street Music"
#                                     ]
#                     )
#                 })

#             wandb.save("model.h5")

#         wandb.log({"ävg_val_acc": sum(avg_validation_acc)/len(avg_validation_acc)})
#         # End the run

# # run.finish()

"""Hyperparamter Tuning"""

def get_optimizer(model, hyperparameters):
    if hyperparameters.optimizer == "sgd":
        return torch.optim.SGD(model.parameters(), lr=hyperparameters.lr, momentum=hyperparameters.momentum, nesterov=hyperparameters.nesterov, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "momentum":
        return torch.optim.SGD(model.parameters(), lr=hyperparameters.lr, momentum=hyperparameters.momentum, nesterov=False, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "nesterov":
        return torch.optim.SGD(model.parameters(), lr=hyperparameters.lr, momentum=hyperparameters.momentum, nesterov=True, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "rmsprop":
        return torch.optim.RMSprop(model.parameters(), lr=hyperparameters.lr, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "adam":
        return torch.optim.Adam(model.parameters(), lr=hyperparameters.lr, weight_decay=hyperparameters.weight_decay)
    else:
        raise ValueError("Invalid optimizer name")

# Hyperparamter tuning
# Sweep configuration
sweep_config = {
    'method': 'grid',  # can be 'grid', 'random', or 'bayes'
    'metric': {'goal': 'maximize', 'name': 'Validation Accuracy'},
    'parameters': {
        'lr': {
            'values': [0.001, 0.01, 0.005]
        },
        'momentum': {
            'values': [0.9, 0.5, 0.99]
        },
        'nesterov': {
            'values': [True, False]
        },
        'weight_decay': {
            'values': [0.010, 0.001, 0.05]
        },
        'num_epochs': {
            'values': [20]
        },
        'optimizer': {
            'values': ["sgd","momentum","nesterov","rmsprop","adam"]
        },
        'weight_initialisation': {
            'values': ["random","xavier"]
        }
    }
}


#  # Get the hyperparameters
# hyperparameters = wandb.config
sweep_id = wandb.sweep(sweep_config, project="1DCNN_Hyperparameter_Tuning") #1DCNN_Hyperparameter_tuning{hyperparameters}

def train():

    # Initialize a new wandb run
    run = wandb.init(project=f"1DCNN_Hyperparameter_Tuning") #1DCNN_Hyperparameter_tuning{hyperparameters}

    # Get the hyperparameters
    hyperparameters = wandb.config

    # The model, optimizer, and loss
    model = AudioClassifier(num_classes=10)
    optimizer = get_optimizer(model, hyperparameters)
    criterion = nn.CrossEntropyLoss()

    wandb.watch(model, criterion, log="all")

    # Define the scheduler
    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.00001)

    # Data Setup
    test_samp = 1 #""" Do not change this!! """
    valid_samp = 4 # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
    batch_size = 16 # Free to change #16 working
    num_workers = 4 # Free to change
    custom_data_module = CustomDataModule(batch_size=batch_size,
                                        num_workers=num_workers,
                                        data_directory=path,
                                        data_frame=df,
                                        validation_fold=valid_samp,
                                        testing_fold=test_samp,  # set to 0 for no test set
                                        esc_10_flag=True,
                                        file_column='filename',
                                        label_column='category',
                                        sampling_rate=44100,
                                        new_sampling_rate=16000,  # new sample rate for input
                                        sample_length_seconds=1  # new length of input in seconds
                                        )

    custom_data_module.setup()



    # wandb.init()


    # Dataloader(s)
    train_loader_fold = custom_data_module.train_dataloader()
    val_loader_fold = custom_data_module.val_dataloader()
    test_loader = custom_data_module.test_dataloader()


    for epoch in range(hyperparameters.num_epochs):
            model.train()
            running_loss = 0.0
            total_samples = 0
            total_correct = 0
            for i, data in enumerate(train_loader_fold, 0):
                inputs, labels = data
                inputs =  inputs.view( inputs.size(0), -1,  inputs.size(-1))
                optimizer.zero_grad()
                outputs = model(inputs)

                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                running_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total_samples += labels.size(0)
                total_correct += (predicted == labels).sum().item()

                # Step the scheduler
                scheduler.step(epoch + i / len(train_loader))

            # Log loss and accuracy
            running_accuracy = 100 * total_correct / total_samples
            wandb.log({"Epoch": epoch, "Training Loss": running_loss, "Training Accuracy": running_accuracy})

    avg_validation_acc = []
    # Validation phase
    model.eval()
    running_loss = 0.0
    total_samples = 0
    total_correct = 0
    with torch.no_grad():
        for inputs, labels in val_loader_fold:
            inputs = inputs.view(inputs.size(0), -1, inputs.size(-1))
            outputs = model(inputs)

            running_loss += calculate_loss(criterion, outputs, labels)
            _, predicted = torch.max(outputs.data, 1)
            total_samples += labels.size(0)
            total_correct += (predicted == labels).sum().item()

    # Log validation loss and accuracy
    running_accuracy = 100 * total_correct / total_samples
    wandb.log({"Validation Loss": running_loss, "Validation Accuracy": running_accuracy})


    avg_validation_acc.append(running_accuracy)
    wandb.log({"ävg_val_acc": sum(avg_validation_acc)/len(avg_validation_acc)})
    # End the run
    # run.finish()

wandb.agent(sweep_id, train, count = 5)

"""**Total no. of trainable and non-trainable parameters**"""

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
non_trainable_params = total_params - trainable_params

print("Total Params: ", total_params)
print("Trainable Params: ", trainable_params)
print("Non-Trainable Params: ", non_trainable_params)

# Installing the requirements
print('Installing Requirements... ',end='')
!pip install lightning
!pip3 install wandb
print('Done')

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from sklearn.model_selection import KFold
from torch.utils.data import Subset
import wandb
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix
from torch.utils.data import ConcatDataset
from torch.utils.data import DataLoader, Subset
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, f1_score

# Importing Libraries
print('Importing Libraries... ',end='')
import os
from pathlib import Path
import pandas as pd
# from torchsummary import summary
import torchaudio
import zipfile
from torchaudio.transforms import Resample
import IPython.display as ipd
from matplotlib import pyplot as plt
from tqdm import tqdm
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
import torch

from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, f1_score
print('Done')

# # Extract data
# with zipfile.ZipFile("/teamspace/studios/this_studio/audio8k.zip", 'r') as zip_ref:
#     zip_ref.extractall("/teamspace/studios/this_studio/audio8k")

# Loading dataset
path = Path('/teamspace/studios/this_studio/audio8k')
df = pd.read_csv('/teamspace/studios/this_studio/audio8k/meta/esc50.csv')

# Getting list of raw audio files
wavs = list(path.glob('audio/*'))  # List all audio files in the 'audio' directory using pathlib.Path.glob

# Visualizing data
waveform, sample_rate = torchaudio.load(str(wavs[0]))  # Load the waveform and sample rate of the first audio file using torchaudio

print("Shape of waveform: {}".format(waveform.size()))  # Print the shape of the waveform tensor
print("Sample rate of waveform: {}".format(sample_rate))  # Print the sample rate of the audio file

# Plot the waveform using matplotlib
plt.figure()
plt.plot(waveform.t().numpy())  # Transpose and convert the waveform tensor to a NumPy array for plotting


# Display the audio using IPython.display.Audio
ipd.Audio(waveform, rate=sample_rate)  # Create an interactive audio player for the loaded waveform

class CustomDataset(Dataset):
    def __init__(self, dataset, **kwargs):
        # Initialize CustomDataset object with relevant parameters
        # dataset: "train", "val", or "test"
        # kwargs: Additional parameters like data directory, dataframe, folds, etc.

        # Extract parameters from kwargs
        self.data_directory = kwargs["data_directory"]
        self.data_frame = kwargs["data_frame"]
        self.validation_fold = kwargs["validation_fold"]
        self.testing_fold = kwargs["testing_fold"]
        self.esc_10_flag = kwargs["esc_10_flag"]
        self.file_column = kwargs["file_column"]
        self.label_column = kwargs["label_column"]
        self.sampling_rate = kwargs["sampling_rate"]
        self.new_sampling_rate = kwargs["new_sampling_rate"]
        self.sample_length_seconds = kwargs["sample_length_seconds"]

        # Filter dataframe based on esc_10_flag and data_type
        if self.esc_10_flag:
            self.data_frame = self.data_frame.loc[self.data_frame['esc10'] == True]

        if dataset == "train":
            self.data_frame = self.data_frame.loc[
                (self.data_frame['fold'] != self.validation_fold) & (self.data_frame['fold'] != self.testing_fold)]
        elif dataset == "val":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.validation_fold]
        elif dataset == "test":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.testing_fold]

        # Get unique categories from the filtered dataframe
        self.categories = sorted(self.data_frame[self.label_column].unique())

        # Initialize lists to hold file names, labels, and folder numbers
        self.file_names = []
        self.labels = []

        # Initialize dictionaries for category-to-index and index-to-category mapping
        self.category_to_index = {}
        self.index_to_category = {}

        for i, category in enumerate(self.categories):
            self.category_to_index[category] = i
            self.index_to_category[i] = category

        # Populate file names and labels lists by iterating through the dataframe
        for ind in tqdm(range(len(self.data_frame))):
            row = self.data_frame.iloc[ind]
            file_path = self.data_directory / "audio" / row[self.file_column]
            self.file_names.append(file_path)
            self.labels.append(self.category_to_index[row[self.label_column]])

        self.resampler = torchaudio.transforms.Resample(self.sampling_rate, self.new_sampling_rate)

        # Window size for rolling window sample splits (unfold method)
        if self.sample_length_seconds == 2:
            self.window_size = self.new_sampling_rate * 2
            self.step_size = int(self.new_sampling_rate * 0.75)
        else:
            self.window_size = self.new_sampling_rate
            self.step_size = int(self.new_sampling_rate * 0.5)

    def __getitem__(self, index):
        # Split audio files with overlap, pass as stacked tensors tensor with a single label
        path = self.file_names[index]
        audio_file = torchaudio.load(str(path), format=None, normalize=True)
        audio_tensor = self.resampler(audio_file[0])

        # Normalize the audio tensor
        audio_tensor = (audio_tensor - audio_tensor.mean()) / audio_tensor.std()

        splits = audio_tensor.unfold(1, self.window_size, self.step_size)
        samples = splits.permute(1, 0, 2)
        return samples, self.labels[index]

    def __len__(self):
        return len(self.file_names)

class CustomDataModule(pl.LightningDataModule):
    def __init__(self, **kwargs):
        # Initialize the CustomDataModule with batch size, number of workers, and other parameters
        super().__init__()
        self.batch_size = kwargs["batch_size"]
        self.num_workers = kwargs["num_workers"]
        self.data_module_kwargs = kwargs

    def setup(self, stage=None):
        # Define datasets for training, validation, and testing during Lightning setup

        # If in 'fit' or None stage, create training and validation datasets
        if stage == 'fit' or stage is None:
            self.training_dataset = CustomDataset(dataset="train", **self.data_module_kwargs)
            self.validation_dataset = CustomDataset(dataset="val", **self.data_module_kwargs)

        # If in 'test' or None stage, create testing dataset
        if stage == 'test' or stage is None:
            self.testing_dataset = CustomDataset(dataset="test", **self.data_module_kwargs)

    def train_dataloader(self):
        # Return DataLoader for training dataset
        return DataLoader(self.training_dataset,
                          batch_size=self.batch_size,
                          shuffle=True,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def val_dataloader(self):
        # Return DataLoader for validation dataset
        return DataLoader(self.validation_dataset,
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def test_dataloader(self):
        # Return DataLoader for testing dataset
        return DataLoader(self.testing_dataset,
                          batch_size=16, #16
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def collate_function(self, data):
        """
        Collate function to process a batch of examples and labels.

        Args:
            data: a tuple of 2 tuples with (example, label) where
                example are the split 1 second sub-frame audio tensors per file
                label = the label

        Returns:
            A list containing examples (concatenated tensors) and labels (flattened tensor).
        """
        examples, labels = zip(*data)
        examples = torch.stack(examples)
        examples = examples.view(examples.size(0), 9, -1)
        labels = torch.flatten(torch.tensor(labels))


        return [examples, labels]

# Data Setup
test_samp = 1 #""" Do not change this!! """
valid_samp = 4 # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
batch_size = 16 # Free to change #16 working
num_workers = 4 # Free to change
custom_data_module = CustomDataModule(batch_size=batch_size,
                                      num_workers=num_workers,
                                      data_directory=path,
                                      data_frame=df,
                                      validation_fold=valid_samp,
                                      testing_fold=test_samp,  # set to 0 for no test set
                                      esc_10_flag=True,
                                      file_column='filename',
                                      label_column='category',
                                      sampling_rate=44100,
                                      new_sampling_rate=16000,  # new sample rate for input
                                      sample_length_seconds=1  # new length of input in seconds
                                      )

custom_data_module.setup()

# Data Exploration
print('Class Label: ', custom_data_module.training_dataset[0][1])  # this prints the class label
print('Shape of data sample tensor: ', custom_data_module.training_dataset[0][0].shape)  # this prints the shape of the sample (Frames, Channel, Features)

# Dataloader(s)
train_loader = custom_data_module.train_dataloader()
val_loader = custom_data_module.val_dataloader()
test_loader = custom_data_module.test_dataloader()

print(len(train_loader.dataset))
inp_data, labels = next(iter(train_loader))
print("Input data:", inp_data.shape)
print("Labels:    ", labels)

x = next(iter(custom_data_module.train_dataloader()))
y = next(iter(custom_data_module.val_dataloader()))
z = next(iter(custom_data_module.test_dataloader()))
print('Train Dataloader:')
print(x)
print('Validation Dataloader:')
print(y)
print('Test Dataloader:')
print(z)

"""# Architecture"""

class CNN1DModule(nn.Module):
    def __init__(self, input_channels=9, num_classes=10):
        super(CNN1DModule, self).__init__()
        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=80, stride=4)
        self.bn1 = nn.BatchNorm1d(128)
        self.pool1 = nn.MaxPool1d(4)
        self.conv2 = nn.Conv1d(128, 128, kernel_size=3)
        self.bn2 = nn.BatchNorm1d(128)
        self.pool2 = nn.MaxPool1d(4)
        self.conv3 = nn.Conv1d(128, 256, kernel_size=3)
        self.bn3 = nn.BatchNorm1d(256)
        self.pool3 = nn.MaxPool1d(4)
        self.conv4 = nn.Conv1d(256, 512, kernel_size=3)
        self.bn4 = nn.BatchNorm1d(512)
        self.pool4 = nn.MaxPool1d(4)
        self.avgPool = nn.AdaptiveAvgPool1d(1)  # avgPool to make it invariant to input size

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(self.bn1(x))
        x = self.pool1(x)
        x = self.conv2(x)
        x = F.relu(self.bn2(x))
        x = self.pool2(x)
        x = self.conv3(x)
        x = F.relu(self.bn3(x))
        x = self.pool3(x)
        x = self.conv4(x)
        x = F.relu(self.bn4(x))
        x = self.pool4(x)
        x = self.avgPool(x)

        # x = x.view(x.size(0), -1)

        # print("shape after passing thorugh CNN", x.shape)
        return x

class MultiHeadAttention(nn.Module):
    def __init__(self, hidden_size, num_heads): # embed_dim
        super(MultiHeadAttention, self).__init__()
        self.multihead_attn = nn.MultiheadAttention(hidden_size, num_heads)     # embed_dim

    def forward(self, query, key, value):
        attn_output, attn_output_weights = self.multihead_attn(query, key, value)
        return attn_output, attn_output_weights

class TransformerEncoder(nn.Module):
    def __init__(self, hidden_size, num_heads_list, num_layers=2, ff_hidden_size=256, dropout=0.005):
        super(TransformerEncoder, self).__init__()

        # Multi-Head Self-Attention Blocks
        self.attention_blocks = nn.ModuleList([
            MultiHeadAttention(hidden_size, num_heads) for _ in range(num_layers) for num_heads in num_heads_list
        ])

        # Feedforward Layers
        self.feedforward = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_size, ff_hidden_size),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(ff_hidden_size, hidden_size),
            ) for _ in range(num_layers)
        ])

        # Layer Normalization
        self.layer_norms_1 = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])
        self.layer_norms_2 = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])

    def forward(self, x):
        for attention_block, feedforward, layer_norm_1, layer_norm_2 in zip(self.attention_blocks, self.feedforward, self.layer_norms_1, self.layer_norms_2):
            # Multi-Head Self-Attention and LayerNorm
            x_temp, _ = attention_block(x, x, x)
            x = x + layer_norm_1(x_temp)

            # Feedforward and LayerNorm
            x_temp = feedforward(x)
            x = x + layer_norm_2(x_temp)

        return x

class ConvTransformerAudioClassifier(nn.Module):
    def __init__(self, hidden_size, num_classes, num_heads_list):
        super(ConvTransformerAudioClassifier, self).__init__()

        # 1D Convolutional Layer for Feature Extraction
        self.conv1d = CNN1DModule()

        # Transformer Encoder
        self.transformer_encoder = TransformerEncoder(hidden_size, num_heads_list)

        # MLP Head for Classification
        self.mlp_head = nn.Sequential(
            nn.Linear(hidden_size, num_classes)
        )

        # CLS token
        self.cls_token = nn.Parameter(torch.zeros(1, 1, hidden_size))

    def forward(self, x):
        # 1D Convolutional Layers
        x = self.conv1d(x)
        x = x.permute(0, 2, 1)      # print("x after permute", x.shape) # x after permute torch.Size([16, 1, 512])

        # Add CLS token
        cls_tokens = self.cls_token.expand(x.size(0),-1, -1) # print("cls_token_shape", cls_tokens.shape)  # cls_token_shape torch.Size([1, 16, 512])

        x = torch.cat((cls_tokens, x), dim=1)    # print("after concate nation", x.shape)

        # Transformer Encoder
        x = self.transformer_encoder(x)
        # print("after encoder", x.shape)

        # Use the representation of CLS token
        x = x[:, 1, :]

        # MLP Head for Classification
        x = self.mlp_head(x)

        x = F.log_softmax(x, dim=-1)

        return x

def calculate_accuracy(outputs, labels):
    _, predicted = torch.max(outputs.data, 1)
    total = labels.size(0)
    correct = (predicted == labels).sum().item()
    return 100 * correct / total

def calculate_loss(criterion, outputs, labels):
    return criterion(outputs, labels).item()

! wandb login 11cb64ddf316ba2bd6cae84ceec30b3f88625c67

"""K-fold Validation with  heads [1,2,4]"""

# # epochs
# num_epoch = 100
# avg_validation_acc = []
# num_heads_list = [1, 2, 4]

# for fold in range(2,6):
#     for heads in num_heads_list:
#         # Initialize a new wandb run
#         run = wandb.init(project=f" CNNTransformer, Fold {fold}, Head {heads}")

#         # # Get the hyperparameters
#         # hyperparameters = wandb.config
#         # print("hyper", hyperparameters)

#         # The model, optimizer, and loss
#         model = ConvTransformerAudioClassifier(hidden_size=512, num_classes=10, num_heads_list=[heads])
#         optimizer = torch.optim.SGD(
#                                     model.parameters(),
#                                     lr=0.001,
#                                     momentum=0.9,
#                                     nesterov=True,
#                                     weight_decay=0.001
#                                 )

#         criterion = nn.CrossEntropyLoss()

#         #wandb.watch(model, criterion, log="all")

#         # Data Setup
#         test_samp = 1 #""" Do not change this!! """
#         valid_samp = fold # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
#         batch_size = 16 # Free to change #16 working
#         num_workers = 4 # Free to change
#         custom_data_module = CustomDataModule(batch_size=batch_size,
#                                             num_workers=num_workers,
#                                             data_directory=path,
#                                             data_frame=df,
#                                             validation_fold=valid_samp,
#                                             testing_fold=test_samp,  # set to 0 for no test set
#                                             esc_10_flag=True,
#                                             file_column='filename',
#                                             label_column='category',
#                                             sampling_rate=44100,
#                                             new_sampling_rate=16000,  # new sample rate for input
#                                             sample_length_seconds=1  # new length of input in seconds
#                                             )

#         custom_data_module.setup()

#         print(f"Training fold {fold}")

#         # wandb.init()


#         # Dataloader(s)
#         train_loader_fold = custom_data_module.train_dataloader()
#         val_loader_fold = custom_data_module.val_dataloader()
#         test_loader = custom_data_module.test_dataloader()


#         for epoch in range(num_epoch):
#             model.train()
#             running_loss = 0.0
#             total_samples = 0
#             total_correct = 0
#             for i, data in enumerate(train_loader_fold, 0):
#                 inputs, labels = data
#                 inputs =  inputs.view(inputs.size(0), -1,  inputs.size(-1))
#                 optimizer.zero_grad()
#                 outputs = model(inputs)

#                 loss = criterion(outputs, labels)
#                 loss.backward()
#                 optimizer.step()

#                 running_loss += loss.item()
#                 _, predicted = torch.max(outputs.data, 1)
#                 total_samples += labels.size(0)
#                 total_correct += (predicted == labels).sum().item()

#                 # # Step the scheduler
#                 # scheduler.step(epoch + i / len(train_loader))

#             # Log loss and accuracy
#             running_accuracy = 100 * total_correct / total_samples
#             wandb.log({"Epoch": epoch, "Training Loss": running_loss, "Training Accuracy": running_accuracy})

#         # Validation phase
#         model.eval()
#         running_loss = 0.0
#         total_samples = 0
#         total_correct = 0
#         with torch.no_grad():
#             for inputs, labels in val_loader_fold:
#                 inputs = inputs.view(inputs.size(0), -1, inputs.size(-1))
#                 outputs = model(inputs)

#                 running_loss += calculate_loss(criterion, outputs, labels)
#                 _, predicted = torch.max(outputs.data, 1)
#                 total_samples += labels.size(0)
#                 total_correct += (predicted == labels).sum().item()

#         # Log validation loss and accuracy
#         running_accuracy = 100 * total_correct / total_samples
#         wandb.log({"Epoch": epoch, "Validation Loss": running_loss, "Validation Accuracy": running_accuracy})


#         avg_validation_acc.append(running_accuracy)


#         # Testing phase
#         model.eval()
#         running_loss = 0.0
#         total_samples = 0
#         total_correct = 0

#         with torch.no_grad():
#             for inputs, labels in test_loader:
#                 inputs = inputs.view(inputs.size(0), -1, inputs.size(-1))
#                 outputs = model(inputs)
#                 _, predicted = torch.max(outputs.data, 1)
#                 total_samples += labels.size(0)
#                 total_correct += (predicted == labels).sum().item()

#                 running_loss += calculate_loss(criterion, outputs, labels)
#                 running_accuracy = 100 * total_correct / total_samples

#                 # Calculate test F1 Score
#                 test_f1 = f1_score(labels, predicted, average='weighted')

#                 # Log test loss and accuracy
#                 wandb.log({"Test Loss": running_loss, "Test Accuracy": running_accuracy, "Test F1 Score": test_f1})

#                 # Call the function to calculate and log ROC curves
#                 wandb.log({"roc" : wandb.plot.roc_curve(labels.detach().numpy(), outputs.detach().numpy(),  # outputs
#                                                             labels = [
#                                                             "Air Conditioner",
#                                                             "Car Horn",
#                                                             "Children Playing",
#                                                             "Dog Bark",
#                                                             "Drilling",
#                                                             "Engine Idling",
#                                                             "Gun Shot",
#                                                             "Jackhammer",
#                                                             "Siren",
#                                                             "Street Music"
#                                                         ]
#                                                         , classes_to_plot=None)})

#                 # Log Precision-Recall curve (for binary or specific class in multi-class)
#                 wandb.log({"pr" : wandb.plot.pr_curve(labels.detach().numpy(), outputs.detach().numpy(),
#                                                          labels = [
#                                                             "Air Conditioner",
#                                                             "Car Horn",
#                                                             "Children Playing",
#                                                             "Dog Bark",
#                                                             "Drilling",
#                                                             "Engine Idling",
#                                                             "Gun Shot",
#                                                             "Jackhammer",
#                                                             "Siren",
#                                                             "Street Music"
#                                                         ]
#                                                         , classes_to_plot=None)})

#                 # Log confusion matrix
#                 wandb.log({
#                     "conf_mat": wandb.plot.confusion_matrix(
#                         probs=None,
#                         y_true=labels.detach().numpy(),
#                         preds=outputs.argmax(dim=1).detach().numpy(),
#                         class_names= [
#                                         "Air Conditioner",
#                                         "Car Horn",
#                                         "Children Playing",
#                                         "Dog Bark",
#                                         "Drilling",
#                                         "Engine Idling",
#                                         "Gun Shot",
#                                         "Jackhammer",
#                                         "Siren",
#                                         "Street Music"
#                                     ]
#                     )
#                 })

#             wandb.save("model.h5")

#         wandb.log({"ävg_val_acc": sum(avg_validation_acc)/len(avg_validation_acc)})
#         # End the run

# # run.finish()

"""Hyperparameter Tuning"""

def get_optimizer(model, hyperparameters):
    if hyperparameters.optimizer == "sgd":
        return torch.optim.SGD(model.parameters(), lr=hyperparameters.lr, momentum=hyperparameters.momentum, nesterov=hyperparameters.nesterov, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "momentum":
        return torch.optim.SGD(model.parameters(), lr=hyperparameters.lr, momentum=hyperparameters.momentum, nesterov=False, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "nesterov":
        return torch.optim.SGD(model.parameters(), lr=hyperparameters.lr, momentum=hyperparameters.momentum, nesterov=True, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "rmsprop":
        return torch.optim.RMSprop(model.parameters(), lr=hyperparameters.lr, weight_decay=hyperparameters.weight_decay)
    elif hyperparameters.optimizer == "adam":
        return torch.optim.Adam(model.parameters(), lr=hyperparameters.lr, weight_decay=hyperparameters.weight_decay)
    else:
        raise ValueError("Invalid optimizer name")

# Hyperparamter tuning
# Sweep configuration
sweep_config = {
    'method': 'grid',  # can be 'grid', 'random', or 'bayes'
    'metric': {'goal': 'maximize', 'name': 'Validation Accuracy'},
    'parameters': {
        'lr': {
            'values': [0.001, 0.01, 0.005]
        },
        'momentum': {
            'values': [0.9, 0.5, 0.99]
        },
        'nesterov': {
            'values': [True, False]
        },
        'weight_decay': {
            'values': [0.010, 0.001, 0.05]
        },
        'num_epochs': {
            'values': [20]
        },
        'optimizer': {
            'values': ["sgd","momentum","nesterov","rmsprop","adam"]
        },
        'weight_initialisation': {
            'values': ["random","xavier"]
        }
    }
}


#  # Get the hyperparameters
# hyperparameters = wandb.config
sweep_id = wandb.sweep(sweep_config, project="1D_CNN_Transformer_Hyperparameter_Tuning") #1DCNN_Hyperparameter_tuning{hyperparameters}

def train():

    # Initialize a new wandb run
    run = wandb.init(project=f"1D_CNN_Transformer_Hyperparameter_Tuning") #1DCNN_Hyperparameter_tuning{hyperparameters}

    # Get the hyperparameters
    hyperparameters = wandb.config

    # The model, optimizer, and loss
    model = ConvTransformerAudioClassifier(hidden_size=512, num_classes=10, num_heads_list=[4])
    optimizer = get_optimizer(model, hyperparameters)
    criterion = nn.CrossEntropyLoss()

    wandb.watch(model, criterion, log="all")

    # Define the scheduler
    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.00001)

    # Data Setup
    test_samp = 1 #""" Do not change this!! """
    valid_samp = 4 # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
    batch_size = 16 # Free to change #16 working
    num_workers = 4 # Free to change
    custom_data_module = CustomDataModule(batch_size=batch_size,
                                        num_workers=num_workers,
                                        data_directory=path,
                                        data_frame=df,
                                        validation_fold=valid_samp,
                                        testing_fold=test_samp,  # set to 0 for no test set
                                        esc_10_flag=True,
                                        file_column='filename',
                                        label_column='category',
                                        sampling_rate=44100,
                                        new_sampling_rate=16000,  # new sample rate for input
                                        sample_length_seconds=1  # new length of input in seconds
                                        )

    custom_data_module.setup()



    # wandb.init()


    # Dataloader(s)
    train_loader_fold = custom_data_module.train_dataloader()
    val_loader_fold = custom_data_module.val_dataloader()
    test_loader = custom_data_module.test_dataloader()


    for epoch in range(hyperparameters.num_epochs):
            model.train()
            running_loss = 0.0
            total_samples = 0
            total_correct = 0
            for i, data in enumerate(train_loader_fold, 0):
                inputs, labels = data
                inputs =  inputs.view( inputs.size(0), -1,  inputs.size(-1))
                optimizer.zero_grad()
                outputs = model(inputs)

                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                running_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total_samples += labels.size(0)
                total_correct += (predicted == labels).sum().item()

                # Step the scheduler
                scheduler.step(epoch + i / len(train_loader))

            # Log loss and accuracy
            running_accuracy = 100 * total_correct / total_samples
            wandb.log({"Epoch": epoch, "Training Loss": running_loss, "Training Accuracy": running_accuracy})


    avg_validation_acc = []

    # Validation phase
    model.eval()
    running_loss = 0.0
    total_samples = 0
    total_correct = 0
    with torch.no_grad():
        for inputs, labels in val_loader_fold:
            inputs = inputs.view(inputs.size(0), -1, inputs.size(-1))
            outputs = model(inputs)

            running_loss += calculate_loss(criterion, outputs, labels)
            _, predicted = torch.max(outputs.data, 1)
            total_samples += labels.size(0)
            total_correct += (predicted == labels).sum().item()

    # Log validation loss and accuracy
    running_accuracy = 100 * total_correct / total_samples
    wandb.log({"Validation Loss": running_loss, "Validation Accuracy": running_accuracy})


    avg_validation_acc.append(running_accuracy)
    wandb.log({"ävg_val_acc": sum(avg_validation_acc)/len(avg_validation_acc)})
    # End the run
    # run.finish()

wandb.agent(sweep_id, train, count = 5)

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
non_trainable_params = total_params - trainable_params

print("Total Params: ", total_params)
print("Trainable Params: ", trainable_params)
print("Non-Trainable Params: ", non_trainable_params)

